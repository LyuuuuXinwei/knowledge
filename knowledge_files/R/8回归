用预测变量来预测响应变量
拟合回归模型
鉴别模型潜在问题
变量选择问题
一般性问题 模型在现实世界的表现
相对重要性问题 预测变量的权重

回归类型很多
OLS最小二乘回归法，包括简单线性，多项式，多元线性回归
llogistic回归，泊松回归

1.判断影响因变量的自变量和他们的相对重要性，得到统计模型
2.应用统计模型到新的现实问题中
3.统计离群点往往有重大发现

简单线性回归
多项式回归
多元线性回归

ols回归
myfit<-lm(Y~col1+col2,df) Y为预测
summary(myfit)展示拟合模型的详细结果
coefficients(myfit) 列出模型参数
fitted(myfit) 列出预测值
plot()+abline(myfit)
多项式：
myfit<-lm(Y~col1+I(col2^2),df) 二次项 高次类似
多元：
1.相关系数：
cor(df)
2.自变量与因变量之间的散点图矩阵：
library(car)
scatterplotMatrix(df,spread=FALSE)
3.回归
fit<-lm(col~col1+col2+col3,data=df)
有交互项的
fit<-lm(col~col1+col2+col3:col4,data=df)

==================================================
回归诊断
残差值：真实值与预测值只差
标准方法:
看拟合诊断图，反馈，二次拟合
par(mfrow=c(2,2))
plot(fit)
myfit<-lm(Y~col1+I(col2^2),df[-c(13,15),]) 剔除强影响点
还有：
car包的诊断函数
正态性：
library(car)
fit<-lm()
qqplot(fit,)参数略
误差独立性：
durbinWatsonTest(fit)
线性
crplot(fit) 非线性则需尝试log 多项式回归
同方差性：
ncvTeat(fit)
spreadLevelPlot(fit)

线性模型架设的综合诊断
g<-gvlma(fit)
summery(g)

======================================================================
观测异常值
离群点
car包检测：
outlierTest(fit)
高杠杆值点
hat.plot(fit)自编函数
强影响点
绘制cook's D图形
变量添加图
avplots()

改进措施
1.删除离群点
2.变量变换，开方log高次幂
3.增删变量

模型选择
anova(fit1,fit2)比较两个回归模型
AIC(fit1,fit2)
逐步回归
逐步添加变量/删除
MASS包
fit<-lm(col~col1,col2,col3,data=df)
stepAIC(fit,direction='backward'/'forward')

深层次分析
交叉验证
相符重要性