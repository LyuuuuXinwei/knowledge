数据聚合和分组运算

groupby
grouped_data=frame['data'].groupby(frame['key']['key2']) grouped_data是GroupBy对象 key层次化分组聚合为双层series
key可以是任何长度一样的ndarray，可以理解为临时先新加了几列进去然后同上
key还可以是索引，传入索引名 层次化索引level=''
key还可以是字典，长度超过会自动裁掉
key还可以是series，字典式的，key索引，value值
frame.groupby() 非Key列都会被聚合，非数值列在使用一些统计函数时会被除去
grouped_data.mean()
grouped_data.size()
grouped_data.count()
默认行聚合

对分组迭代
for a,b in frame.groupby('key'): key就两类数据
    frame_a=a
    frame_b=b
分表
pieces=dict(list(frame.groupby('key')))
pieces['a']
同上frame_a 像字典一样分表
grouped=frame.groupby(frame.dtypes,axis=1)
按类型

选取一个或一组列
frame['data'].groupby(frame['key']) 简写：frame.groupby('key')['data']
大数据集往往经常只需要对部分列聚合

通过函数分组
frame.groupby(len).sum() 按照行索引的字符串长度分组

以上所有分组方式都可以组合使用
==================================================================================================

数据聚合
使用自己编写的聚合函数：
grouped=df.groupby('')
def f(arr):
    return arr.max()-arr.min()
grouped.agg(my_func) agg('mean')
grouped.describe() 返回一堆标准函数

面向列的多函数应用
grouped.agg([('name1','mean'),('name2',my_func)]) 重命名多函数
多函数应用于多列，则形成列名在外，函数在内的层次列索引：
g=frame.groupby('key')['data1','data2']
g.agg([])
如果对不同列应用不同的函数：
g=frame.groupby('key')
g.agg({'data1':['func1','func2'],'data2':'func2'})传字典

以无索引形式返回聚合数据
g=frame.groupby('key',as_index=False) 变索引的列不动

==================================================================================================
分组级运算和转换
agg是数据转换的一种，还有其他的
frame.groupby('key').transform('func')
可以理解为将分组聚合后的函数填回原数据位置中，也可以理解为为原数据中的值分组化地使用某个函数

aplly:一般性的拆分-应用-合并
对完整frame使用一个函数：
def f(frame):
f(frame)

对frame的groupby对象apply一个函数，这个函数的参数不是上面的arr，是frame
frame.groupby('').apply(f)

frame.groupby('')[].describe()的本质：
f=lambda x: x.describe()
frame.groupby('')[].apply(f)

frame.groupby('',group_keys=False).apply(f) 索引回到列

分数位和桶分析
可以理解为用cut和qcut的分段而不是现成的一个列来分组，相当于先加了个cut过的分段列，然后分组
factor=pd.cut(frame.column1,n) 长度相同的桶，想得到大小相等的桶就用qcut
grouped=frame.column2.groupby(factor) factor是key
grouped.apply(my_func)

示例：用特定于分组的值填充缺失值
用数据集衍生值填充缺失值：
obj/frame.fillna(obj.mean())
不同分组填不同的值：用fillna构造函数传给apply
简写一些索引的做法：key=['']*4+['']*3
用分组平均值填充NA：
fill_mean=lambda x: x.fillna(x.mean())
frame.groupby('key').apply(fill_mean)

示例：随机采样和排列
def take(obj,n=5):
    return obj.take(np.random.permutation(len(obj))[:n])
take(obj)
随机排列取前N：完全随机打乱
如果想要分组抽样：
condition=lambda x:x[-1] 扑克牌例子，索引的最后一位是花色
obj.groupby(condition).apply(obj,n=2)

示例：分组加权平均数和相关系数
dataframe列与列，两个series之间的运算，如加权平均
grouped=df.groupby('category')
get_wavg=lambda x: np.average(x['data'],weights=x['weights'])
grouped.apply(get_wavg)
grouped.appply(lambda x:x['col1'].corr(x['cor2']))

示例：面向分组的线性回归
import statsmodels.api as sm 统计类的函数包

====================================================================================================
透视表和交叉表
frame.pivot_table([1col1','col2'],rows=['分组索引1','分组索引2'],cols='列的分组索引',margins=True,aggfunc=len/count,fill_value=0)
pivot_table的默认聚合类型是分组平均数，aggfunc=len/count/sum
margins=True分项小计
fill_value=0空的组合NA
交叉表：计算分组频率的特殊透视表
pd.crosstab([frame.col1,frame.col],frame.col2,margins=True)
必传参数1是将来的行标，2是列标

==============================
例子，选举

为相似表述内容的元素做归并
f=lambda x:reflection_dict.get(x,x) reflection_dict是归并字典，如果x不存在则返回x本身
frame.col=frame.col.map(f) map 元素级别的用法 ，新行赋值

清洗掉不满足要求的行
frame=frame[frame.col>0,frame.col2<1000]

为大数据集准备子集
fra=frame[frame.col.isin(['',''])]为正态八成的数据建立子集

基于一个列创建新列
frame[new_col]=frame.col.map(f) f可以是个字典

from mpl_toolkits.basemap import Basemap,cm
from matplotlib import rcParams
from matplotlib.collections import LineCollection
from shapelib import ShapeFile
import dbflib